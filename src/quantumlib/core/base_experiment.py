#!/usr/bin/env python3
"""
Base Experiment Class - å®Ÿé¨“åŸºåº•ã‚¯ãƒ©ã‚¹
ã™ã¹ã¦ã®é‡å­å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã®åŸºåº•ã¨ãªã‚‹ã‚¯ãƒ©ã‚¹
"""

import time
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any

from .data_manager import SimpleDataManager

# OQTOPUS imports
try:
    from qiskit.qasm3 import dumps
    from quri_parts_oqtopus.backend import OqtopusSamplingBackend

    OQTOPUS_AVAILABLE = True
except ImportError:
    OQTOPUS_AVAILABLE = False
    OqtopusSamplingBackend = None


class BaseExperiment(ABC):
    """
    é‡å­å®Ÿé¨“ã®åŸºåº•ã‚¯ãƒ©ã‚¹

    ã™ã¹ã¦ã®å…·ä½“çš„ãªå®Ÿé¨“ã‚¯ãƒ©ã‚¹ï¼ˆCHSHExperimentç­‰ï¼‰ãŒã“ã‚Œã‚’ç¶™æ‰¿
    å…±é€šæ©Ÿèƒ½ï¼šOQTOPUSæ¥ç¶šã€ä¸¦åˆ—å®Ÿè¡Œã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†
    """

    def __init__(
        self,
        experiment_name: str = None,
        oqtopus_backend: Any | None = None,
    ):
        """
        Initialize base experiment

        Args:
            experiment_name: å®Ÿé¨“å
            oqtopus_backend: OQTOPUSãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ä½œæˆï¼‰
        """
        self.experiment_name = (
            experiment_name or f"{self.__class__.__name__.lower()}_{int(time.time())}"
        )
        self.data_manager = SimpleDataManager(self.experiment_name)

        # OQTOPUSãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®š
        if oqtopus_backend:
            self.oqtopus_backend = oqtopus_backend
            self.oqtopus_available = True
        else:
            self.oqtopus_available = OQTOPUS_AVAILABLE
            if OQTOPUS_AVAILABLE:
                self.oqtopus_backend = OqtopusSamplingBackend()
            else:
                self.oqtopus_backend = None

        # ãƒ­ãƒ¼ã‚«ãƒ«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼è¨­å®š
        self.local_simulator = None
        try:
            from qiskit_aer import AerSimulator

            self.local_simulator = AerSimulator()
            self.local_simulator_available = True
        except ImportError:
            self.local_simulator_available = False

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOQTOPUSè¨­å®š
        self.anemone_basis_gates = ["sx", "x", "rz", "cx"]
        self.transpiler_options = {
            "basis_gates": self.anemone_basis_gates,
            "optimization_level": 1,
        }
        self.mitigation_options = {
            "ro_error_mitigation": "pseudo_inverse",
        }

        # OQTOPUSç”¨ã®å†…éƒ¨æ§‹é€ 
        self.transpiler_info = {
            "transpiler_lib": "qiskit",
            "transpiler_options": self.transpiler_options,
        }
        self.mitigation_info = self.mitigation_options

        print(f"{self.__class__.__name__}: {self.experiment_name}")
        print(f"OQTOPUS: {'Available' if self.oqtopus_available else 'Not available'}")
        print(
            f"Local Simulator: {'Available' if self.local_simulator_available else 'Not available'}"
        )

    def submit_circuit_to_oqtopus(
        self, circuit: Any, shots: int, device_id: str
    ) -> str | None:
        """
        å˜ä¸€å›è·¯ã‚’OQTOPUSã«æŠ•å…¥
        """
        if not self.oqtopus_available:
            print("OQTOPUS not available")
            return None

        try:
            # QASM3ç”Ÿæˆ
            qasm_str = dumps(circuit)
            f"circuit_{int(time.time())}"

            # è¨­å®šå‹•çš„æ›´æ–°
            self.transpiler_info["transpiler_options"] = self.transpiler_options
            self.mitigation_info = self.mitigation_options

            job = self.oqtopus_backend.sample_qasm(
                qasm_str,
                device_id=device_id,
                shots=shots,
                transpiler_info=self.transpiler_info,
                mitigation_info=self.mitigation_info,
            )

            return job.job_id

        except Exception as e:
            print(f"OQTOPUS submission failed: {e}")
            return None

    def run_circuit_locally(self, circuit: Any, shots: int) -> dict[str, Any] | None:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œ
        """
        if not self.local_simulator_available:
            return None

        try:
            import uuid

            from qiskit import transpile

            # å›è·¯ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ‘ã‚¤ãƒ«
            compiled_circuit = transpile(circuit, self.local_simulator)

            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            job = self.local_simulator.run(compiled_circuit, shots=shots)
            result = job.result()
            counts = result.get_counts()

            job_id = str(uuid.uuid4())[:8]

            return {
                "job_id": job_id,
                "counts": dict(counts),
                "shots": shots,
                "success": True,
                "simulator": "local",
            }

        except Exception as e:
            print(f"Local simulation failed: {e}")
            return None

    def submit_circuits_parallel(
        self,
        circuits: list[Any],
        devices: list[str] = ["qulacs"],
        shots: int = 1024,
        parallel_workers: int = 4,
    ) -> dict[str, list[str]]:
        """
        è¤‡æ•°å›è·¯ã‚’ä¸¦åˆ—æŠ•å…¥ï¼ˆæ”¹å–„ç‰ˆï¼‰
        """
        print(
            f"Submitting {len(circuits)} circuits to {len(devices)} devices using {parallel_workers} workers"
        )

        if not self.oqtopus_available:
            print("OQTOPUS not available, falling back to local simulation...")
            if self.local_simulator_available:
                return self.submit_circuits_locally(circuits, devices, shots)
            else:
                print("Local simulator also not available")
                return {device: [] for device in devices}

        all_job_ids = {device: [] for device in devices}
        submission_tasks = []

        def submit_single_circuit(circuit, device, index):
            try:
                job_id = self.submit_circuit_to_oqtopus(circuit, shots, device)
                if job_id:
                    print(
                        f"Circuit {index + 1}/{len(circuits)} â†’ {device}: {job_id[:8]}..."
                    )
                    return device, job_id
                else:
                    print(f"Circuit {index + 1}/{len(circuits)} â†’ {device}: failed")
                    return device, None
            except Exception as e:
                print(f"âŒ Circuit {index + 1} submission error: {e}")
                return device, None

        with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
            # é †åºã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ã€futureã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒšã‚¢ã‚’ä¿å­˜
            future_to_info = {}
            for device in devices:
                for i, circuit in enumerate(circuits):
                    future = executor.submit(submit_single_circuit, circuit, device, i)
                    future_to_info[future] = (device, i)
                    submission_tasks.append(future)

            # çµæœã‚’é †åºä»˜ãã§åé›†
            device_results = {device: [None] * len(circuits) for device in devices}
            for future in as_completed(submission_tasks):
                device, job_id = future.result()
                original_device, original_index = future_to_info[future]
                if job_id:
                    device_results[original_device][original_index] = job_id

            # å¤±æ•—ã—ãŸã‚¸ãƒ§ãƒ–ã«ã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼job_idã‚’è¨­å®š
            for device in devices:
                final_job_ids = []
                for i, job_id in enumerate(device_results[device]):
                    if job_id is not None:
                        final_job_ids.append(job_id)
                    else:
                        # å¤±æ•—ã—ãŸå ´åˆã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼job_idã‚’ç”Ÿæˆ
                        failed_job_id = f"failed_{device}_{i}_{int(time.time())}"
                        final_job_ids.append(failed_job_id)
                all_job_ids[device] = final_job_ids

        for device, jobs in all_job_ids.items():
            print(f"âœ… {device}: {len(jobs)} jobs submitted")

        return all_job_ids

    def submit_circuits_locally(
        self, circuits: list[Any], devices: list[str] = ["qulacs"], shots: int = 1024
    ) -> dict[str, list[str]]:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ç”¨ã®å›è·¯æŠ•å…¥ï¼ˆå³åº§ã«çµæœã‚‚å–å¾—ï¼‰
        """
        print(f"Running {len(circuits)} circuits locally...")

        all_job_ids = {}

        for device in devices:
            device_jobs = []

            for i, circuit in enumerate(circuits):
                result = self.run_circuit_locally(circuit, shots)
                if result:
                    job_id = result["job_id"]
                    device_jobs.append(job_id)

                    # çµæœã‚’å†…éƒ¨ã«ä¿å­˜ï¼ˆå¾Œã§collectã§å–å¾—ï¼‰
                    if not hasattr(self, "_local_results"):
                        self._local_results = {}
                    self._local_results[job_id] = result

                    print(
                        f"Circuit {i + 1}/{len(circuits)} â†’ {device}: {job_id} (local)"
                    )
                else:
                    # å¤±æ•—ã—ãŸå ´åˆã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼job_idã‚’ç”Ÿæˆ
                    failed_job_id = f"failed_{device}_{i}_{int(time.time())}"
                    device_jobs.append(failed_job_id)

                    # å¤±æ•—çµæœã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
                    if not hasattr(self, "_local_results"):
                        self._local_results = {}
                    self._local_results[failed_job_id] = {
                        "job_id": failed_job_id,
                        "success": False,
                        "counts": {},
                        "error": "Local simulation failed",
                    }

                    print(f"Circuit {i + 1}/{len(circuits)} â†’ {device}: failed")

            all_job_ids[device] = device_jobs
            print(f"{device}: {len(device_jobs)} circuits completed locally")

        return all_job_ids

    def get_oqtopus_result(
        self, job_id: str, timeout_minutes: int = 30, verbose_log: bool = False
    ) -> dict[str, Any] | None:
        """
        OQTOPUSçµæœå–å¾—ï¼ˆæ­£ã—ã„ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—å¯¾å¿œï¼‰
        """
        # å¤±æ•—ã—ãŸã‚¸ãƒ§ãƒ–ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®å ´åˆ
        if job_id.startswith("failed_"):
            return {
                "job_id": job_id,
                "success": False,
                "counts": {},
                "error": "Job submission failed",
            }

        # ãƒ­ãƒ¼ã‚«ãƒ«çµæœãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
        if hasattr(self, "_local_results") and job_id in self._local_results:
            return self._local_results[job_id]

        if not self.oqtopus_available:
            return None

        import time

        max_retries = 5
        retry_delay = 2  # åˆæœŸå¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰

        for attempt in range(max_retries):
            try:
                if verbose_log and attempt > 0:
                    print(f"â³ Retry {attempt}/{max_retries} for {job_id[:8]}...")
                elif verbose_log:
                    print(f"â³ Waiting for result: {job_id[:8]}...")

                job = self.oqtopus_backend.retrieve_job(job_id)

                # æ­£ã—ã„ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—æ–¹æ³•ã‚’ä½¿ç”¨
                try:
                    job_dict = job._job.to_dict()
                    status = job_dict.get("status", "unknown")

                    if verbose_log:
                        print(f"ğŸ” {job_id[:8]} status: {status}")

                    # æˆåŠŸçŠ¶æ…‹ã®å ´åˆ
                    if status == "succeeded":
                        try:
                            result = job.result()
                            if result and hasattr(result, "counts"):
                                counts = result.counts
                                return {
                                    "job_id": job_id,
                                    "counts": dict(counts),
                                    "shots": sum(counts.values()),
                                    "status": status,
                                    "success": True,
                                }
                        except Exception as result_error:
                            if verbose_log:
                                print(
                                    f"âš ï¸ Result extraction failed for {job_id[:8]}: {result_error}"
                                )

                    # æ˜ç¢ºã«å¤±æ•—ã—ãŸå ´åˆã¯å³åº§ã«çµ‚äº†
                    elif status in ["failed", "cancelled", "error"]:
                        return {
                            "job_id": job_id,
                            "status": status,
                            "success": False,
                            "error": f"Job {status}",
                        }

                    # readyçŠ¶æ…‹ã®å ´åˆã¯çµæœå–å¾—ã‚’è©¦è¡Œ
                    elif status == "ready":
                        try:
                            result = job.result()
                            if result and hasattr(result, "counts"):
                                counts = result.counts
                                return {
                                    "job_id": job_id,
                                    "counts": dict(counts),
                                    "shots": sum(counts.values()),
                                    "status": status,
                                    "success": True,
                                }
                        except Exception as ready_error:
                            if verbose_log:
                                print(
                                    f"âš ï¸ Ready result extraction failed for {job_id[:8]}: {ready_error}"
                                )

                    # ã¾ã å‡¦ç†ä¸­ã®çŠ¶æ…‹ï¼ˆsubmitted, running, queuedç­‰ï¼‰ã®å ´åˆ
                    elif status in ["submitted", "running", "queued", "pending"]:
                        if attempt < max_retries - 1:  # æœ€å¾Œã®è©¦è¡Œã§ãªã‘ã‚Œã°å¾…æ©Ÿ
                            wait_time = retry_delay * (2**attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                            if verbose_log:
                                print(
                                    f"âŒ› Job {job_id[:8]} still {status}, waiting {wait_time}s..."
                                )
                            time.sleep(wait_time)
                            continue
                        else:
                            # æœ€å¾Œã®è©¦è¡Œã§ã‚‚å‡¦ç†ä¸­ã®å ´åˆ
                            return {
                                "job_id": job_id,
                                "status": status,
                                "success": False,
                                "error": f"Job timeout in {status} state",
                            }

                    # ä¸æ˜ãªçŠ¶æ…‹ã®å ´åˆ
                    else:
                        if attempt < max_retries - 1:
                            wait_time = retry_delay
                            if verbose_log:
                                print(
                                    f"â“ Unknown status {status} for {job_id[:8]}, waiting {wait_time}s..."
                                )
                            time.sleep(wait_time)
                            continue
                        else:
                            return {
                                "job_id": job_id,
                                "status": status,
                                "success": False,
                                "error": f"Unknown job status: {status}",
                            }

                except Exception as status_error:
                    if verbose_log:
                        print(
                            f"âš ï¸ Status check failed for {job_id[:8]} (attempt {attempt + 1}): {status_error}"
                        )

                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—§å¼ãƒ¡ã‚½ãƒƒãƒ‰ã§resultå–å¾—ã‚’è©¦è¡Œ
                    try:
                        result = job.result()
                        if result and hasattr(result, "counts"):
                            counts = result.counts
                            return {
                                "job_id": job_id,
                                "counts": dict(counts),
                                "shots": sum(counts.values()),
                                "success": True,
                            }
                    except Exception:
                        pass

                    # æœ€å¾Œã®è©¦è¡Œã§ãªã‘ã‚Œã°å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        continue

            except Exception as e:
                if verbose_log:
                    print(
                        f"âŒ Result collection failed for {job_id[:8]} (attempt {attempt + 1}): {e}"
                    )

                # æœ€å¾Œã®è©¦è¡Œã§ãªã‘ã‚Œã°å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue

        # å…¨ã¦ã®è©¦è¡ŒãŒå¤±æ•—ã—ãŸå ´åˆ
        return {
            "job_id": job_id,
            "status": "timeout",
            "success": False,
            "error": f"Failed after {max_retries} attempts",
        }

    def collect_results_parallel(
        self, job_ids: dict[str, list[str]], wait_minutes: int = 30
    ) -> dict[str, list[dict[str, Any]]]:
        """
        çµæœã‚’ä¸¦åˆ—åé›†
        """
        print(f"Collecting results from {len(job_ids)} devices...")

        # ãƒ­ãƒ¼ã‚«ãƒ«çµæœãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®é«˜é€Ÿå‡¦ç†
        if hasattr(self, "_local_results"):
            print("Using local simulation results...")
            all_results = {}
            for device, device_job_ids in job_ids.items():
                device_results = []
                for job_id in device_job_ids:
                    if job_id in self._local_results:
                        result = self._local_results[job_id]
                        device_results.append(result)
                        print(f"{device}: {job_id[:8]}... collected (local)")
                all_results[device] = device_results
                print(f"{device}: {len(device_results)} results collected")
            return all_results

        if not self.oqtopus_available:
            print("OQTOPUS not available")
            return {}

        def collect_from_device(device_data):
            device, device_job_ids = device_data
            device_results = [None] * len(device_job_ids)

            # é †åºã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ä¸€ç·’ã«çµæœã‚’åé›†
            for i, job_id in enumerate(device_job_ids):
                result = self.get_oqtopus_result(job_id, wait_minutes, verbose_log=True)
                if result and result.get("success", False):
                    device_results[i] = result
                    print(f"âœ… {device}: {job_id[:8]}... collected")
                else:
                    status = result.get("status", "unknown") if result else "no_result"
                    print(f"âŒ {device}: {job_id[:8]}... failed (status: {status})")

            # é †åºã‚’ä¿æŒã™ã‚‹ãŸã‚ã€Noneã‚‚ãã®ã¾ã¾è¿”ã™
            return device, device_results

        all_results = {}

        # ä¸¦åˆ—åé›†
        with ThreadPoolExecutor(max_workers=len(job_ids)) as executor:
            futures = [
                executor.submit(collect_from_device, item) for item in job_ids.items()
            ]

            for future in as_completed(futures):
                device, results = future.result()
                all_results[device] = results
                print(f"âœ… {device}: {len(results)} results collected")

        return all_results

    # æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ï¼šå„å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…
    @abstractmethod
    def create_circuits(self, **kwargs) -> list[Any]:
        """å®Ÿé¨“å›ºæœ‰ã®å›è·¯ä½œæˆï¼ˆå„å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    @abstractmethod
    def analyze_results(
        self, results: dict[str, list[dict[str, Any]]], **kwargs
    ) -> dict[str, Any]:
        """å®Ÿé¨“å›ºæœ‰ã®çµæœè§£æï¼ˆå„å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    @abstractmethod
    def save_experiment_data(
        self, results: dict[str, Any], metadata: dict[str, Any] = None
    ) -> str:
        """å®Ÿé¨“å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆå„å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    # å…±é€šä¿å­˜ãƒ¡ã‚½ãƒƒãƒ‰
    def save_job_ids(
        self,
        job_ids: dict[str, list[str]],
        metadata: dict[str, Any] = None,
        filename: str = "job_ids",
    ) -> str:
        """ã‚¸ãƒ§ãƒ–IDä¿å­˜"""
        save_data = {
            "job_ids": job_ids,
            "submitted_at": time.time(),
            "experiment_type": self.__class__.__name__,
            "oqtopus_config": {
                "transpiler_options": self.transpiler_options,
                "mitigation_options": self.mitigation_options,
                "basis_gates": self.anemone_basis_gates,
            },
            "metadata": metadata or {},
        }
        return self.data_manager.save_data(save_data, filename)

    def save_raw_results(
        self,
        results: dict[str, Any],
        metadata: dict[str, Any] = None,
        filename: str = "raw_results",
    ) -> str:
        """ç”Ÿçµæœä¿å­˜"""
        save_data = {
            "results": results,
            "saved_at": time.time(),
            "experiment_type": self.__class__.__name__,
            "oqtopus_available": self.oqtopus_available,
            "metadata": metadata or {},
        }
        return self.data_manager.save_data(save_data, filename)

    def save_experiment_summary(self) -> str:
        """å®Ÿé¨“ã‚µãƒãƒªãƒ¼ä¿å­˜"""
        return self.data_manager.summary()

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ï¼šå…¨ä½“çš„ãªå®Ÿé¨“ãƒ•ãƒ­ãƒ¼
    def run_experiment(
        self,
        devices: list[str] = ["qulacs"],
        shots: int = 1024,
        submit_interval: float = 1.0,
        wait_minutes: int = 30,
        **kwargs,
    ) -> dict[str, Any]:
        """
        å®Ÿé¨“å®Ÿè¡Œã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰
        å„å®Ÿé¨“ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½
        """
        print(f"Running {self.__class__.__name__}")

        # 1. å›è·¯ä½œæˆï¼ˆå®Ÿé¨“å›ºæœ‰ï¼‰
        circuits = self.create_circuits(**kwargs)
        print(f"Created {len(circuits)} circuits")

        # 2. ä¸¦åˆ—æŠ•å…¥
        job_ids = self.submit_circuits_parallel(
            circuits, devices, shots, submit_interval
        )

        # 3. çµæœåé›†
        raw_results = self.collect_results_parallel(job_ids, wait_minutes)

        # 4. çµæœè§£æï¼ˆå®Ÿé¨“å›ºæœ‰ï¼‰
        analyzed_results = self.analyze_results(raw_results, **kwargs)

        # 5. ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆå®Ÿé¨“å›ºæœ‰ï¼‰
        save_path = self.save_experiment_data(analyzed_results)

        print(f"{self.__class__.__name__} completed")
        print(f"Results saved: {save_path}")

        return {
            "job_ids": job_ids,
            "raw_results": raw_results,
            "analyzed_results": analyzed_results,
            "experiment_metadata": {
                "experiment_type": self.__class__.__name__,
                "devices": devices,
                "shots": shots,
                "circuits_count": len(circuits),
            },
        }
